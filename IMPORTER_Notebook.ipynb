{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72e9961e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyodbc\n",
    "import pandas as pd\n",
    "\n",
    "# Path to the Access database file\n",
    "mdb_file = r\"C:\\Users\\gia.luongdo\\Desktop\\ERP-Importer\\db_Artikel_Export2.mdb\"\n",
    "conn_str = (\n",
    "    query = \"\"\"\n",
    "SELECT \n",
    "    m.ArtBasis AS aid,\n",
    "    sku.ArtikelCode AS variant_aid,\n",
    "    'classification_system' AS classification_system,\n",
    "    'attribute[0]' AS [attribute[0]],\n",
    "    '' AS [attribute_value[0]],\n",
    "    '' AS [is_mandatory[0]],\n",
    "    '' AS production_type\n",
    "FROM t_Art_Mega_SKU sku\n",
    "INNER JOIN t_Art_MegaBase m ON sku.ArtNr = m.ArtNr\n",
    "WHERE m.Marke IN ('Corporate', 'EXCD', 'XO')\n",
    "\"\"\"\n",
    "df = pd.read_sql(query, conn)\n",
    "    f\"DBQ={mdb_file};\"\n",
    ")\n",
    "\n",
    "# Connect to Access database\n",
    "conn = pyodbc.connect(conn_str)\n",
    "\n",
    "# Query data from table\n",
    "query = \"SELECT * FROM t_Art_Mega_SKU\"\n",
    "df = pd.read_sql(query, conn)\n",
    "\n",
    "# Export to CSV file\n",
    "df.to_csv(r\"C:\\Users\\gia.luongdo\\Desktop\\ERP-Importer\\exported_data.csv\", index=False, encoding='utf-8', sep=',')\n",
    "\n",
    "conn.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16034bcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tổng số giá trị kiểm tra trong 'aid': 168\n",
      "Số lượng giá trị trong 'AID': 173\n",
      "\n",
      "Các giá trị trong 'aid' KHÔNG trùng khớp với giá trị nào trong 'AID':\n",
      "1046.0\n",
      "1050.0\n",
      "1051.0\n",
      "1060.0\n",
      "1090.0\n",
      "110.0\n",
      "120.0\n",
      "1400.0\n",
      "1410.0\n",
      "1425.0\n",
      "1450.0\n",
      "1451.0\n",
      "1460.0\n",
      "1465.0\n",
      "1505.0\n",
      "1515.0\n",
      "1525.0\n",
      "1545.0\n",
      "1560.0\n",
      "1565.0\n",
      "160.0\n",
      "1600.0\n",
      "1650.0\n",
      "1680.0\n",
      "1699.0\n",
      "1700.0\n",
      "1751.0\n",
      "1781.0\n",
      "1790.0\n",
      "195.0\n",
      "2049.0\n",
      "2075.0\n",
      "2111.0\n",
      "2112.0\n",
      "2180.0\n",
      "2181.0\n",
      "2190.0\n",
      "2199.0\n",
      "2899.0\n",
      "3005.0\n",
      "3011.0\n",
      "3012.0\n",
      "3025.0\n",
      "3070.0\n",
      "3075.0\n",
      "3077.0\n",
      "3081.0\n",
      "3082.0\n",
      "3083.0\n",
      "3084.0\n",
      "3085.0\n",
      "3086.0\n",
      "3087.0\n",
      "3088.0\n",
      "3089.0\n",
      "309.0\n",
      "3090.0\n",
      "3095.0\n",
      "3099.0\n",
      "3100.0\n",
      "311.0\n",
      "3185.0\n",
      "3190.0\n",
      "3325.0\n",
      "3400.0\n",
      "3407.0\n",
      "349.0\n",
      "352.0\n",
      "3520.0\n",
      "3521.0\n",
      "356.0\n",
      "3560.0\n",
      "3561.0\n",
      "3580.0\n",
      "3590.0\n",
      "399.0\n",
      "4000.0\n",
      "4001.0\n",
      "4005.0\n",
      "4020.0\n",
      "4025.0\n",
      "404.0\n",
      "4040.0\n",
      "4081.0\n",
      "4085.0\n",
      "4095.0\n",
      "4097.0\n",
      "4099.0\n",
      "4100.0\n",
      "4120.0\n",
      "4150.0\n",
      "4250.0\n",
      "4400.0\n",
      "4405.0\n",
      "4520.0\n",
      "4525.0\n",
      "4590.0\n",
      "4600.0\n",
      "4605.0\n",
      "4900.0\n",
      "4910.0\n",
      "4920.0\n",
      "5025.0\n",
      "5050.0\n",
      "5052.0\n",
      "5077.0\n",
      "508.0\n",
      "5080.0\n",
      "5099.0\n",
      "518.0\n",
      "5181.0\n",
      "5182.0\n",
      "5270.0\n",
      "5275.0\n",
      "5290.0\n",
      "5295.0\n",
      "5300.0\n",
      "5390.0\n",
      "5500.0\n",
      "6099.0\n",
      "6300.0\n",
      "6305.0\n",
      "6310.0\n",
      "6315.0\n",
      "6900.0\n",
      "6905.0\n",
      "6910.0\n",
      "6915.0\n",
      "7001.0\n",
      "7200.0\n",
      "7205.0\n",
      "7548.0\n",
      "7549.0\n",
      "7621.0\n",
      "7622.0\n",
      "7631.0\n",
      "7632.0\n",
      "7634.0\n",
      "7635.0\n",
      "7700.0\n",
      "7705.0\n",
      "7720.0\n",
      "7725.0\n",
      "7806.0\n",
      "7811.0\n",
      "7820.0\n",
      "7821.0\n",
      "7830.0\n",
      "7835.0\n",
      "7840.0\n",
      "7845.0\n",
      "7850.0\n",
      "7855.0\n",
      "7860.0\n",
      "7865.0\n",
      "7910.0\n",
      "7911.0\n",
      "7921.0\n",
      "7925.0\n",
      "7961.0\n",
      "7965.0\n",
      "7971.0\n",
      "798.0\n",
      "7981.0\n",
      "7985.0\n",
      "8001.0\n",
      "8005.0\n",
      "8100.0\n",
      "Tổng cộng: 168\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# --- Đọc dữ liệu ---\n",
    "file_to_compare = r\"C:\\Users\\gia.luongdo\\Desktop\\AID_SQL_.csv\"\n",
    "column1_name = 'aid'\n",
    "column2_name = 'AID'\n",
    "csv_delimiter = ','\n",
    "\n",
    "try:\n",
    "    df = pd.read_csv(file_to_compare, delimiter=csv_delimiter)\n",
    "\n",
    "    # Kiểm tra sự tồn tại của các cột cần thiết\n",
    "    if column1_name not in df.columns or column2_name not in df.columns:\n",
    "        print(f\"Lỗi: Thiếu một trong hai cột '{column1_name}' hoặc '{column2_name}'. Các cột có sẵn: {df.columns.tolist()}\")\n",
    "        raise SystemExit\n",
    "\n",
    "    aid_list = df[column1_name].dropna().astype(str).str.strip().tolist()\n",
    "    AID_list = df[column2_name].dropna().astype(str).str.strip().tolist()\n",
    "\n",
    "    khong_trung_khop = []\n",
    "    for aid in aid_list:\n",
    "        if aid not in AID_list:\n",
    "            khong_trung_khop.append(aid)\n",
    "\n",
    "    print(f\"Tổng số giá trị kiểm tra trong '{column1_name}': {len(aid_list)}\")\n",
    "    print(f\"Số lượng giá trị trong '{column2_name}': {len(AID_list)}\")\n",
    "\n",
    "    if khong_trung_khop:\n",
    "        print(f\"\\nCác giá trị trong '{column1_name}' KHÔNG trùng khớp với giá trị nào trong '{column2_name}':\")\n",
    "        for v in khong_trung_khop:\n",
    "            print(v)\n",
    "        print(f\"Tổng cộng: {len(khong_trung_khop)}\")\n",
    "    else:\n",
    "        print(f\"Tất cả giá trị trong '{column1_name}' đều có trong '{column2_name}'.\")\n",
    "\n",
    "except FileNotFoundError:\n",
    "    print(f\"Lỗi: Không tìm thấy file '{file_to_compare}'.\")\n",
    "except Exception as e:\n",
    "    print(f\"Lỗi: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1975025a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gia.luongdo\\AppData\\Local\\Temp\\ipykernel_25400\\1300257503.py:27: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\gia.luongdo\\AppData\\Local\\Temp\\ipykernel_25400\\1300257503.py:114: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  classification_df = pd.read_sql(classification_query, conn)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data exported to C:\\Users\\gia.luongdo\\Desktop\\ERP-Importer\\IMPORTER_SKU_Neuanlage_Basis.csv\n",
      "Data exported to C:\\Users\\gia.luongdo\\Desktop\\ERP-Importer\\IMPORTER_SKU_CLASSIFICATION_Classification_Basis.csv\n",
      "Data exported to C:\\Users\\gia.luongdo\\Desktop\\ERP-Importer\\IMPORTER_SKU_Keyword.csv\n",
      "Data exported to C:\\Users\\gia.luongdo\\Desktop\\ERP-Importer\\IMPORTER_SKU_EAN.csv\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\gia.luongdo\\AppData\\Local\\Temp\\ipykernel_25400\\1300257503.py:227: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\gia.luongdo\\AppData\\Local\\Temp\\ipykernel_25400\\1300257503.py:248: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n",
      "C:\\Users\\gia.luongdo\\AppData\\Local\\Temp\\ipykernel_25400\\1300257503.py:257: UserWarning: pandas only supports SQLAlchemy connectable (engine/connection) or database string URI or sqlite3 DBAPI2 connection. Other DBAPI2 objects are not tested. Please consider using SQLAlchemy.\n",
      "  df = pd.read_sql(query, conn)\n"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "import pyodbc\n",
    "import pandas as pd\n",
    "from datetime import datetime\n",
    "\n",
    "mdb_file = r\"C:\\Users\\gia.luongdo\\Desktop\\ERP-Importer\\db_Artikel_Export2.mdb\"\n",
    "sku_basis_csv = r\"C:\\Users\\gia.luongdo\\Desktop\\ERP-Importer\\IMPORTER_SKU_Neuanlage_Basis.csv\"\n",
    "conn_str = (\n",
    "    r\"DRIVER={Microsoft Access Driver (*.mdb, *.accdb)};\"\n",
    "    f\"DBQ={mdb_file};\"\n",
    ")\n",
    "# Configure logging to write to a file\n",
    "logging.basicConfig(\n",
    "    filename='importer_log.txt',\n",
    "    filemode='a',\n",
    "    format='%(asctime)s - %(levelname)s - %(message)s',\n",
    "    level=logging.INFO)\n",
    "# Connect to the Access database\n",
    "conn = pyodbc.connect(conn_str)\n",
    "logging.info(\"Connected to the database successfully.\")\n",
    "#IMPORTER_ARTICLE_Neuanlage_Basis:\n",
    "#Reads data from the database\n",
    "def read_and_write_aku_data():\n",
    "    table_name = 't_Art_Mega_SKU'\n",
    "    query = f\"SELECT sku.ArtikelCode AS SKU, m.Ursprungsland, t.ArtBem AS name FROM (t_Art_Mega_SKU sku INNER JOIN t_Art_Text_DE t ON sku.ArtNr = t.ArtNr) INNER JOIN t_Art_MegaBase m ON sku.ArtNR = m.ArtNr WHERE m.Marke IN ('Corporate', 'EXCD', 'XO');\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "\n",
    "    # Add columns with specified values\n",
    "    df['company'] = 0\n",
    "    df['automatic_batch_numbering_pattern'] = '{No,000000000}'\n",
    "    df['batch_management'] = 2\n",
    "    df['batch_number_range'] = 'Chargen'\n",
    "    df['batch_numbering_type'] = 3\n",
    "    df['date_requirement'] = 1\n",
    "    df['discountable'] = 'ja'\n",
    "    df['factory'] = 'Düsseldorf'\n",
    "    df['isPi'] = 'ja'\n",
    "    df['isShopArticle'] = 'ja'\n",
    "    df['isSl'] = 'ja'\n",
    "    df['isSt'] = 'ja'\n",
    "    df['isVerifiedArticle'] = 'ja'\n",
    "    df['isCatalogArticle'] = 'ja'\n",
    "    df['unitPi'] = 'Stk'\n",
    "    df['unitSl'] = 'Stk'\n",
    "    df['unitSt'] = 'Stk'\n",
    "    #df['name'] = df['name']\n",
    "    df['replacement_time'] = 1\n",
    "    df['taxPi'] = 'Waren'\n",
    "    df['taxSl'] = 'Waren'\n",
    "    df['valid_from'] = datetime.now().strftime(\"%Y%m%d\")\n",
    "\n",
    "    # Take only first 2 characters from Ursprungsland and rename to 'country', reorder columns\n",
    "    df['country_of_origin'] = df['Ursprungsland'].str[:2]\n",
    "    df = df[['SKU', 'company', 'country_of_origin', 'automatic_batch_numbering_pattern', 'batch_management', 'batch_number_range', 'batch_numbering_type', 'date_requirement', 'discountable', 'factory', 'isPi', 'isShopArticle', 'isSl', 'isSt', 'isVerifiedArticle', 'isCatalogArticle', 'unitPi', 'unitSl', 'unitSt', 'name', 'replacement_time', 'taxPi', 'taxSl', 'valid_from']]\n",
    "\n",
    "    # Write DataFrame to CSV with correct separator and columns\n",
    "    df.to_csv(sku_basis_csv, index=False, encoding='utf-8', sep=',')\n",
    "    print(f'Data exported to {sku_basis_csv}')\n",
    "    logging.info(f'Data exported to {sku_basis_csv}')\n",
    "\n",
    "# IMPORTER_SKU_CLASSIFICATION_Merkmale_Basis\n",
    "def read_and_write_classification_data():\n",
    "    \"\"\"Reads classification data from the database and writes it to a CSV file.\"\"\"\n",
    "    # Define the table name and query\n",
    "    classification_table_name = 't_Art_MegaBase'\n",
    "    table_name = 't_Art_Flags'\n",
    "    classification_query = f\"\"\"\n",
    "        SELECT\n",
    "            sku.ArtikelCode AS SKU,\n",
    "            m.Ursprungsland AS Ursprungsland,\n",
    "            sku.Größe AS Größe,\n",
    "            sku.Größenspiegel AS Größenspiegel,\n",
    "            sku.Hauptfarbe AS Farbgruppe,\n",
    "            sku.FarbeNeu AS Farbe,\n",
    "            sku.isColorCombination AS zweifarbig,\n",
    "            m.Materialart AS Fabric_Herstellung,\n",
    "            sku.ArtSort AS sku_ArtSort,\n",
    "            m.Produktgruppe AS product_group,\n",
    "            m.Marke AS Marke,\n",
    "            m.Grammatur AS Grammatur,\n",
    "            m.Artikel_Partner AS Artikel_Partner,\n",
    "            m.ArtSort AS ArtSort,\n",
    "            m.Zusammensetzung AS Zusammensetzung,\n",
    "            m.Gender AS Gender,\n",
    "            f.flag_workwear AS workwear,\n",
    "            f.flag_veredelung AS veredelung,\n",
    "            f.flag_discharge AS discharge,\n",
    "            f.flag_dtg AS dtg,\n",
    "            f.flag_dyoj AS dyoj,\n",
    "            f.flag_dyop AS dyop,\n",
    "            f.flag_flock AS flock,\n",
    "            f.flag_siebdruck AS siebdruck,\n",
    "            f.flag_stick AS stick,\n",
    "            f.flag_sublimation AS sublimation,\n",
    "            f.flag_transfer AS transfer,\n",
    "            f.flag_premium AS premium,\n",
    "            f.flag_extras AS extras,\n",
    "            f.flag_outdoor AS outdoor,\n",
    "            f.flag_plussize AS oversize,\n",
    "            f.isNoLabel AS label,\n",
    "            f.isErw AS erw,\n",
    "            sku.Karton_Länge as Verpackungslänge,\n",
    "            sku.Karton_Breite as Verpackungsbreite,\n",
    "            sku.Karton_Höhe as Verpackungshoehe,\n",
    "            sku.EAN as EAN,\n",
    "            sku.Produktgewicht as Produktgewicht,\n",
    "            sku.WarenNr as WarenNr\n",
    "        FROM (t_Art_MegaBase m\n",
    "        INNER JOIN t_Art_Flags f ON m.ArtNr = f.ArtNr )\n",
    "        inner join t_Art_Mega_SKU sku on m.ArtNr = sku.ArtNr\n",
    "        WHERE m.Marke IN ('Corporate', 'EXCD', 'XO')\n",
    "    \"\"\"\n",
    "    classification_df = pd.read_sql(classification_query, conn)\n",
    "\n",
    "    # Add columns with specified values\n",
    "    classification_df['company'] = 0\n",
    "    classification_df['classification_system'] = 'Warengruppensystem'\n",
    "    classification_df['product_group_superior'] = classification_df['Marke'] + '||Produktlinie||ROOT'\n",
    "    classification_df['ArtikelCode'] = classification_df['SKU']\n",
    "    classification_df['feature[0]'] = 'Grammatur'\n",
    "    classification_df['feature_value[0]'] = classification_df['Grammatur']\n",
    "    classification_df['feature[1]'] = 'Oeko_MadeInGreen'\n",
    "    classification_df['feature_value[1]'] = ''\n",
    "    classification_df['feature[2]'] = 'Partnerlook'\n",
    "    classification_df['feature_value[2]'] = classification_df['Artikel_Partner'].str[:4]\n",
    "    classification_df['feature[3]'] = 'Sortierung'\n",
    "    classification_df['feature_value[3]'] = classification_df['ArtSort']\n",
    "    classification_df['feature[4]'] = 'Fabric_Herstellung'\n",
    "    classification_df['feature_value[4]'] = classification_df['Fabric_Herstellung']\n",
    "    classification_df['feature[5]'] = 'Material'\n",
    "    classification_df['feature_value[5]'] = classification_df['Zusammensetzung']\n",
    "    classification_df['feature[6]'] = 'Workwear'\n",
    "    classification_df['feature_value[6]'] = abs(classification_df['workwear'])\n",
    "    classification_df['feature[7]'] = 'Produktlinie_Veredelung'\n",
    "    classification_df['feature_value[7]'] = abs(classification_df['veredelung'])\n",
    "    classification_df['feature[8]'] = 'Produktlinie_Veredelungsart_Discharge'\n",
    "    classification_df['feature_value[8]'] = abs(classification_df['discharge'])\n",
    "    classification_df['feature[9]'] = 'Produktlinie_Veredelungsart_DTG'\n",
    "    classification_df['feature_value[9]'] = abs(classification_df['dtg'])\n",
    "    classification_df['feature[10]'] = 'Produktlinie_Veredelungsart_DYOJ'\n",
    "    classification_df['feature_value[10]'] = abs(classification_df['dyoj'])\n",
    "    classification_df['feature[11]'] = 'Produktlinie_Veredelungsart_DYOP'\n",
    "    classification_df['feature_value[11]'] = abs(classification_df['dyop'])\n",
    "    classification_df['feature[12]'] = 'Produktlinie_Veredelungsart_Flock'\n",
    "    classification_df['feature_value[12]'] = abs(classification_df['flock'])\n",
    "    classification_df['feature[13]'] = 'Produktlinie_Veredelungsart_Siebdruck'\n",
    "    classification_df['feature_value[13]'] = abs(classification_df['siebdruck'])\n",
    "    classification_df['feature[14]'] = 'Produktlinie_Veredelungsart_Stick'\n",
    "    classification_df['feature_value[14]'] = abs(classification_df['stick'])\n",
    "    classification_df['feature[15]'] = 'Produktlinie_Veredelungsart_Sublimationsdruck'\n",
    "    classification_df['feature_value[15]'] = abs(classification_df['sublimation'])\n",
    "    classification_df['feature[16]'] = 'Produktlinie_Veredelungsart_Transferdruck'\n",
    "    classification_df['feature_value[16]'] = abs(classification_df['transfer'])\n",
    "    classification_df['feature[17]'] = 'Brand_Premium_Item'\n",
    "    classification_df['feature_value[17]'] = abs(classification_df['premium'])\n",
    "    classification_df['feature[18]'] = 'Extras'\n",
    "    classification_df['feature_value[18]'] = abs(classification_df['extras'])\n",
    "    classification_df['feature[19]'] = 'Kids'\n",
    "    classification_df['feature_value[19]'] = 1 - abs(classification_df['erw'])\n",
    "    classification_df['feature[20]'] = 'Outdoor'\n",
    "    classification_df['feature_value[20]'] = abs(classification_df['outdoor'])\n",
    "    classification_df['feature[21]'] = 'Size_Oversize'\n",
    "    classification_df['feature_value[21]'] = abs(classification_df['oversize'])\n",
    "    classification_df['feature[22]'] = 'Geschlecht'\n",
    "    classification_df['feature_value[22]'] = classification_df['Gender']\n",
    "    classification_df['feature[23]'] = 'Brand_Label'\n",
    "    classification_df['feature_value[23]'] = abs(classification_df['label'])\n",
    "    classification_df['feature[24]'] = 'Farbe'\n",
    "    classification_df['feature_value[24]'] = classification_df['Farbe']\n",
    "    classification_df['feature[25]'] = 'Farbgruppe'\n",
    "    classification_df['feature_value[25]'] = classification_df['Farbgruppe']\n",
    "    classification_df['feature[26]'] = 'Größe'\n",
    "    classification_df['feature_value[26]'] = classification_df['Größe']\n",
    "    classification_df['feature[27]'] = 'Größenspiegel'\n",
    "    classification_df['feature_value[27]'] = classification_df['Größenspiegel']\n",
    "    classification_df['feature[28]'] = 'Zweifarbig'\n",
    "    classification_df['feature_value[28]'] = classification_df['zweifarbig']\n",
    "    classification_df['feature[29]'] = 'Ursprungsland'\n",
    "    classification_df['feature_value[29]'] = classification_df['Ursprungsland'].str[:2]\n",
    "    classification_df['feature[30]'] = 'Verpackungslänge'\n",
    "    classification_df['feature_value[30]'] = classification_df['Verpackungslänge']\n",
    "    classification_df['feature[31]'] = 'Verpackungsbreite'\n",
    "    classification_df['feature_value[31]'] = classification_df['Verpackungsbreite']\n",
    "    classification_df['feature[32]'] = 'Verpackungshoehe'\n",
    "    classification_df['feature_value[32]'] = classification_df['Verpackungshoehe']\n",
    "    classification_df['feature[33]'] = 'EAN'\n",
    "    classification_df['feature_value[33]'] = classification_df['EAN']\n",
    "    classification_df['feature[34]'] = 'Produktgewicht'\n",
    "    classification_df['feature_value[34]'] = classification_df['Produktgewicht']\n",
    "    classification_df['feature[35]'] = 'Statistische Warnennummer'\n",
    "    classification_df['feature_value[35]'] = classification_df['WarenNr']\n",
    "    # Reorder columns\n",
    "    feature_cols = []\n",
    "    for i in range(36):\n",
    "        feature_cols.extend([f'feature[{i}]', f'feature_value[{i}]'])\n",
    "    classification_df = classification_df[\n",
    "        ['SKU', 'company', 'classification_system', 'product_group', 'product_group_superior'] + feature_cols\n",
    "    ]\n",
    "\n",
    "    # Write DataFrame to CSV (add your desired path)\n",
    "    classification_csv = r\"C:\\Users\\gia.luongdo\\Desktop\\ERP-Importer\\IMPORTER_SKU_CLASSIFICATION_Classification_Basis.csv\"\n",
    "    classification_df.to_csv(\n",
    "        classification_csv,\n",
    "        index=False,\n",
    "        encoding='windows-1252',\n",
    "        sep=',',\n",
    "    )\n",
    "    print(f'Data exported to {classification_csv}')\n",
    "    logging.info(f'Data exported to {classification_csv}')\n",
    "\n",
    "#IMPORTER_SKU_Keyword\n",
    "def read_and_write_SKU_Keyword():\n",
    "    table_name = 't_Art_MegaBase'\n",
    "    query = \"\"\"\n",
    "        SELECT \n",
    "            sku.ArtikelCode AS SKU,\n",
    "            0 as company,\n",
    "            t.SuchText as keyword_list,\n",
    "            'de' as language,\n",
    "            ',' as seperator\n",
    "        FROM (t_Art_MegaBase m\n",
    "        INNER JOIN t_Art_Mega_SKU sku ON m.ArtNr = sku.ArtNr)\n",
    "        INNER JOIN t_Art_Text_DE t ON sku.ArtNr = t.ArtNr\n",
    "        WHERE m.Marke IN ('Corporate', 'EXCD', 'XO')\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    Zuordnung_csv = r\"C:\\Users\\gia.luongdo\\Desktop\\ERP-Importer\\IMPORTER_SKU_Keyword.csv\"\n",
    "    df.to_csv(Zuordnung_csv, index=False, encoding='windows-1252', sep=',')\n",
    "    print(f'Data exported to {Zuordnung_csv}')\n",
    "    logging.info(f'Data exported to {Zuordnung_csv}')\n",
    "\n",
    "#Import_SKU_EAN\n",
    "def read_and_write_SKU_EAN():\n",
    "    table_name = 't_Art_MegaBase'\n",
    "    query = \"\"\"\n",
    "        SELECT \n",
    "            sku.ArtikelCode AS SKU,\n",
    "            0 as company,\n",
    "            sku.EAN as ean,\n",
    "            'de' as language,\n",
    "            ',' as seperator\n",
    "        FROM (t_Art_MegaBase m\n",
    "        INNER JOIN t_Art_Mega_SKU sku ON m.ArtNr = sku.ArtNr)\n",
    "        INNER JOIN t_Art_Text_DE t ON sku.ArtNr = t.ArtNr\n",
    "        WHERE m.Marke IN ('Corporate', 'EXCD', 'XO')\n",
    "    \"\"\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "    Zuordnung_csv = r\"C:\\Users\\gia.luongdo\\Desktop\\ERP-Importer\\IMPORTER_SKU_EAN.csv\"\n",
    "    df.to_csv(Zuordnung_csv, index=False, encoding='windows-1252', sep=',')\n",
    "    print(f'Data exported to {Zuordnung_csv}')\n",
    "    logging.info(f'Data exported to {Zuordnung_csv}')\n",
    "\n",
    "#Link SKU and Article Basis\n",
    "def link_sku_article_basis():\n",
    "    query = f\"SELECT sku.ArtikelCode AS SKU, m.ArtBasis as aid, m.ArtNr as ArtNr FROM t_Art_Mega_SKU sku INNER JOIN t_Art_MegaBase m ON sku.ArtNR = m.ArtNr WHERE m.Marke IN ('Corporate', 'EXCD', 'XO');\"\n",
    "    df = pd.read_sql(query, conn)\n",
    "\n",
    "    df.to_csv(r\"C:\\Users\\gia.luongdo\\Desktop\\ERP-Importer\\IMPORTER_SKU_ArtBasis.csv\", index=False, encoding='windows-1252', sep=',')\n",
    "\n",
    "# Call the function to execute the logic\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "conn.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08a4130e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
